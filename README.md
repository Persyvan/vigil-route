# ðŸš— VIGIL-ROUTE: AI Road Defect Detection System

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.19-orange.svg)](https://tensorflow.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Accuracy](https://img.shields.io/badge/Accuracy-87.9%25-brightgreen.svg)]()

**Deep Learning system for automated road defect detection using MobileNetV2**

Developed by **Persy Maki ND** | AI/ML Engineering Student

---

**ðŸŒ Language / Langue:** [ðŸ‡¬ðŸ‡§ English](#) | [ðŸ‡«ðŸ‡· Lire en FranÃ§ais](README_FR.md)

---

## ðŸ“Œ Project Overview

VIGIL-ROUTE is a production-ready computer vision system that identifies road defects (potholes, pavement deformations) from images and videos with **87.9% accuracy**. Designed for smart city infrastructure monitoring and citizen reporting applications (311 systems).

### ðŸŽ¯ Key Features

- **ðŸ§  MobileNetV2 Architecture**: Lightweight CNN optimized for mobile/edge deployment
- **ðŸ“¸ Dual-Mode Operation**: 
  - **Citizen Mode**: Process photos from 311 reporting apps
  - **Fleet Mode**: Real-time dashcam video analysis with HUD overlay
- **ðŸ“Š Automated Reporting**: Excel reports with color-coded urgency + Interactive HTML maps
- **ðŸŒ GPS Integration**: EXIF metadata extraction + intelligent geolocation simulation
- **ðŸš¨ Adaptive Risk Scoring**: Speed-based urgency prioritization algorithm
- **ðŸ’§ Water Resistance**: Trained to detect water-filled potholes (rainy conditions)
- **ðŸ—ºï¸ Geospatial Visualization**: Interactive Folium maps with priority markers

---

## ðŸŽ¬ Demo

### Mode CITIZEN (311 App Simulation)
*Process citizen-reported photos with AI classification and geolocation*

**Input**: 1-3 smartphone photos â†’ **Output**: Annotated images + Excel report + Interactive map

### Mode FLEET (Dashcam Analysis)
*Real-time video processing with Iron Man-style HUD overlay*

**Input**: Dashcam MP4 video â†’ **Output**: Annotated video with detections + GPS tracking

ðŸ“¹ **Full video demo**: [LinkedIn Post](https://linkedin.com/in/persy-maki) *(coming soon)*

---

## ðŸ—ï¸ Technical Architecture

### Model Specifications (V9 - Current)

| Component | Details |
|-----------|---------|
| **Framework** | TensorFlow 2.19.0 |
| **Base Model** | MobileNetV2 (ImageNet pretrained, frozen) |
| **Input Size** | 224Ã—224Ã—3 RGB images |
| **Output Classes** | 3 classes (multi-class classification) |
| **Training Images** | 1,268 images (80% split) |
| **Validation Images** | 159 images (10% split) |
| **Test Images** | 157 images (10% split) |
| **Total Dataset** | **1,584 annotated images** |
| **Test Accuracy** | **87.90%** |
| **Test Loss** | 0.3664 |
| **Inference Time** | ~120ms/image (CPU Colab) |

### Classes

```python
CLASS_NAMES = [
    'deformation_chaussee',  # Pavement deformation
    'nid_de_poule',          # Pothole
    'route_saine'            # Healthy road
]
Data Augmentation Pipeline
python
data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),     # Mirror images
    layers.RandomRotation(0.1),          # Â±10% rotation
    layers.RandomZoom(0.1),              # Â±10% zoom
    layers.RandomContrast(0.2),          # Â±20% contrast (shadows/clouds)
    layers.RandomBrightness(0.2)         # Â±20% brightness (time of day)
], name="data_augmentation")
Purpose: Simulate real-world variations (lighting, angles, weather) to improve generalization.

ðŸ§  Architecture Design Choices
Why MobileNetV2 Over Heavier Models?
VIGIL-ROUTE prioritizes deployability over raw accuracy. Here's why MobileNetV2 was chosen:

Model	Params	Size	Inference (CPU)	Mobile-Ready?	Choice
MobileNetV2	3.5M	14 MB	~120ms	âœ… Yes	SELECTED
ResNet50	25.6M	98 MB	~450ms	âš ï¸ Slow	âŒ
YOLOv8 (detection)	11.2M	44 MB	~200ms	âš ï¸ Heavy	âŒ
EfficientNetB0	5.3M	29 MB	~180ms	âš ï¸ Moderate	âŒ
Key Advantages of MobileNetV2
1. Real-World Deployment Targets

ðŸ“± Citizen Mode: Runs on smartphone (iOS/Android) for 311 apps

ðŸš— Fleet Mode: Deployable on vehicle dashcams with limited compute

âš¡ Edge Computing: Works on Raspberry Pi / NVIDIA Jetson Nano

ðŸŒ Low Bandwidth: Small model size (14 MB) for cloud upload/download

2. Performance Trade-off Analysis

text
MobileNetV2:     87.9% accuracy @ 120ms inference  â† Our choice
ResNet50:        ~91% accuracy @ 450ms inference   (3.75Ã— slower)
YOLOv8:          ~89% accuracy @ 200ms inference   (1.67Ã— slower)
Verdict: 4% accuracy loss for 3-4Ã— faster inference is worth it for mobile deployment.

3. Why NOT Object Detection (YOLOv8)?

VIGIL-ROUTE uses image classification, not object detection, because:

âœ… Faster: Classification is simpler (no bounding box regression)

âœ… Less data-hungry: Requires fewer annotations (class labels vs bounding boxes)

âœ… Sufficient for use case: We need "Is there a defect?" not "Where exactly in the image?"

ðŸ”® Future upgrade: YOLOv8 planned for V10 (precise localization + privacy blur)

4. Production Considerations

Requirement	MobileNetV2	Heavier Models
Smartphone deployment	âœ… Smooth	âŒ Laggy/battery drain
Dashcam integration	âœ… Real-time	âŒ Requires GPU
Cloud costs	âœ… Low (CPU inference)	âŒ High (GPU required)
Citizen adoption	âœ… Fast response	âŒ Slow = frustration
ðŸ“Š Performance Metrics (Test Set - 157 images)
Overall Performance
Metric	Value
Accuracy	87.90%
Loss	0.3664
Precision (weighted avg)	88%
Recall (weighted avg)	88%
F1-Score (weighted avg)	88%
Per-Class Performance
Class	Precision	Recall	F1-Score	Support (Test Images)
deformation_chaussee	85%	91%	88%	76 images
nid_de_poule	83%	74%	79%	47 images
route_saine	100%	100%	100%	34 images
Key Insights:

âœ… Perfect detection of healthy roads (no false alarms)

âœ… High recall for pavement deformations (91% - rarely missed)

âš ï¸ Pothole recall at 74% (conservative detection to avoid false positives on wet roads)

ðŸ—‚ï¸ Dataset Methodology
Collection Strategy
Period: October - December 2025
Location: Montreal, QC, Canada (various neighborhoods)
Device: iPhone (simulating citizen 311 app usage)
Total Images: 1,584 annotated road surfaces

Why October-December 2025?
Strategic seasonal selection to capture Montreal's challenging weather transitions:

Month	Conditions Captured
October	â˜€ï¸ Sunny autumn, dry asphalt, leaf coverage
November	ðŸŒ§ï¸ Frequent rain, wet roads, water-filled potholes
December	â„ï¸ Early winter, light snow, road salt, cold-induced cracks
Key Dataset Features
ðŸ“¸ Real-world iPhone captures (GPS EXIF metadata preserved)

ðŸŒ¦ï¸ Multi-weather robustness: Sunny, rainy, snowy conditions

ðŸ’§ Water-filled pothole detection: V8 threshold optimization eliminated water reflections

ðŸ‚ Seasonal noise resistance: Autumn leaves, shadows, debris

ðŸŽ¯ Balanced class distribution: Prevents model bias

Class Distribution (1,584 total images)
text
deformation_chaussee: ~650 images (41%)
nid_de_poule:         ~580 images (37%)
route_saine:          ~354 images (22%)
Evolution: Binary â†’ Multi-Class
V8 (Binary Model):

Classes: defect vs no_defect

Challenge: Water reflections caused false positives

Solution: Threshold tuning to eliminate water glare

V9 (Current - Multi-Class):

Classes: 3-way classification (deformation, pothole, healthy)

Improved granularity for prioritization

Maintains water resistance from V8

ðŸŒ GPS & Geolocation Strategy
Current Implementation (Prototype Phase)
VIGIL-ROUTE uses a hybrid GPS approach balancing cost and accuracy:

Mode CITIZEN (Image-Based)
Primary Method: EXIF Metadata Extraction

python
# Extract GPS from iPhone/Android photos
gps_coords = extract_gps_exif(image_path)
# Returns: (latitude, longitude) if available
âœ… Advantages:

Free (no API costs)

Works offline

Privacy-friendly (no external tracking)

âš ï¸ Limitations:

Requires EXIF metadata (user must enable location in camera settings)

Low reliability: ~60% of citizen photos lack GPS data

Accuracy: Â±10-50 meters (smartphone GPS)

Fallback: Simulation

If EXIF GPS is absent, system simulates coordinates:

python
gps = simulate_gps_montreal()  # Random coords in Montreal area
gps_reliability = 'SIMULATED'  # Flagged in reports
âš ï¸ Production Recommendation:

For real municipal deployment, use:

ðŸ—ºï¸ Google Maps Geocoding API (paid, $5-7/1000 requests)

ðŸ™ï¸ Municipal 311 API integration (city-provided coordinates)

ðŸ“ Address-based geocoding (ask citizen for street address)

Mode FLEET (Vehicle-Based)
Current: GPS Simulation

python
# Prototype uses fake coordinates for demo
gps = (45.5017 + frame_offset, -73.5673 + frame_offset)
âš ï¸ Production Requirement: OBD-II Hardware

For real fleet deployment, requires:

Component	Purpose	Cost
OBD-II GPS Reader	Real-time vehicle location	~$50-200 USD
Speed Data	Adaptive risk scoring	Included in OBD-II
Timestamp Sync	Frame-GPS alignment	Software-based
Recommended Devices:

FreeMatrix OBD-II GPS (~$60, Bluetooth)

Verizon Hum (~$10/month, cellular)

Automatic Pro (~$130, WiFi + 4G)

âš ï¸ Deployment Constraint:

Fleet mode requires hardware integration beyond software scope. Municipal fleets must:

Install OBD-II readers in vehicles

Configure Bluetooth/WiFi streaming to dashcam device

Integrate OBD data with video pipeline

Current Status: âœ… Software ready | âš ï¸ Hardware integration pending

ðŸš¨ Adaptive Risk Scoring Algorithm
VIGIL-ROUTE doesn't just detect defectsâ€”it prioritizes them based on danger level.

Risk Calculation Formula
python
def analyser_risque(classe, confiance, vitesse):
    """
    Calculate urgency based on:
    - Defect type (pothole = higher risk)
    - AI confidence
    - Vehicle speed (higher speed = higher danger)
    """
    if classe == 'route_saine':
        return "ðŸŸ¢ No Defect", "NONE"
    
    # Base severity score
    score_base = 1.0 if classe == 'nid_de_poule' else 0.7
    
    # Speed amplification factor (exponential)
    facteur_vitesse = 1.0 + (vitesse / 50.0) ** 1.2
    
    # Final danger score
    score_danger = (confiance * score_base) * facteur_vitesse
    
    # Urgency thresholds
    if score_danger >= 1.5:
        return "ðŸ”´ CRITICAL", "IMMEDIATE INTERVENTION"
    elif score_danger >= 1.0:
        return "ðŸŸ  HIGH", "INSPECTION REQUIRED"
    elif score_danger >= 0.7:
        return "ðŸŸ¡ MEDIUM", "MONITORING"
    else:
        return "ðŸŸ¢ LOW", "PREVENTIVE"
Adaptive Detection Thresholds
Speed-based confidence thresholds prevent false positives:

Speed Zone	Pothole Threshold	Deformation Threshold
High (â‰¥70 km/h)	45% confidence	60% confidence
Medium (50-69 km/h)	50% confidence	65% confidence
Low (<50 km/h)	60% confidence	70% confidence
Rationale: Higher speeds require more conservative detection (safety-first approach).

ðŸš€ Quick Start
Prerequisites
Python 3.10+

TensorFlow 2.19+

Google Colab (recommended) or local Jupyter environment

Installation
1. Clone Repository

bash
git clone https://github.com/Persyvan/vigil-route.git
cd vigil-route
2. Install Dependencies

bash
pip install -r requirements.txt
3. Download Model Weights

Model file (89 MB) hosted on Google Drive:

ðŸ“¥ Download vigil_route_classifier_v9_open_world.keras

Place in: models/vigil_route_classifier_v9_open_world.keras

Usage
Mode CITIZEN (Image Analysis)
Google Colab:

python
# Upload notebook: notebooks/VIGIL_Citizen_Mode.ipynb
# Mount Google Drive
# Run all cells
Expected Outputs:

detection_*.jpg - Annotated images with bounding boxes

rapports_citoyens.xlsx - Excel with color-coded urgency

carte_signalements.html - Interactive Folium map

Mode FLEET (Video Analysis)
python
# Upload notebook: notebooks/VIGIL_Fleet_Demo.ipynb
# Provide dashcam MP4 file
# Run cells
Expected Outputs:

Demo_Fleet_Video_[timestamp].mp4 - Annotated video with HUD

Excel report with frame-by-frame detections

GPS trajectory map

ðŸ“ Project Structure
text
vigil-route/
â”œâ”€â”€ README.md                          # English documentation
â”œâ”€â”€ README_FR.md                       # French documentation
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ LICENSE                            # MIT License
â”œâ”€â”€ .gitignore                         # Git exclusions
â”‚
â”œâ”€â”€ notebooks/                         # Jupyter/Colab notebooks
â”‚   â”œâ”€â”€ VIGIL_Citizen_Mode.ipynb      # Image processing mode
â”‚   â””â”€â”€ VIGIL_Fleet_Demo.ipynb        # Video processing mode
â”‚
â”œâ”€â”€ models/                            # Model weights (download separately)
â”‚   â””â”€â”€ README.md                      # Model download instructions
â”‚
â”œâ”€â”€ demo_outputs/                      # Example outputs
â”‚   â”œâ”€â”€ citizen_examples/              # Annotated images
â”‚   â””â”€â”€ fleet_examples/                # Video screenshots
â”‚
â”œâ”€â”€ docs/                              # Additional documentation
â”‚   â”œâ”€â”€ CITIZEN_MODE.md
â”‚   â”œâ”€â”€ FLEET_MODE.md
â”‚   â””â”€â”€ PERFORMANCE.md
â”‚
â””â”€â”€ scripts/                           # Python scripts (future)
    â”œâ”€â”€ citizen_mode.py
    â””â”€â”€ fleet_mode.py
ðŸ”§ Development Status
âœ… Completed (V9)
 MobileNetV2 model training (1,584 images)

 87.9% test accuracy achieved

 Multi-weather dataset (rain, snow, sun)

 Water-filled pothole detection

 Adaptive risk scoring algorithm

 Speed-based threshold tuning

 Citizen mode (image processing)

 Fleet mode (video processing with HUD)

 GPS extraction + simulation

 Excel reports with color-coded urgency

 Interactive HTML maps (Folium)

ðŸš§ In Progress
 Privacy blur (faces/plates) using YOLOv8

 Real OBD-II GPS integration

 Mobile app prototype (Flutter)

 Cloud deployment (AWS Lambda)

ðŸ”® Future Roadmap
 Expand dataset to 5,000+ images (multi-city)

 Real-time edge inference (Raspberry Pi / Jetson Nano)

 Integration with municipal 311 APIs

 Multi-language support (EN/FR/ES)

 Severity scoring refinement

ðŸš› Production Deployment Requirements
Mode FLEET: From Prototype to Municipal Deployment
Current Status: âœ… Proof-of-concept working
Production-Ready: âš ï¸ Requires hardware + professional services

What Works Now (V9)
âœ… AI defect detection (87.9% accuracy)

âœ… Video processing pipeline

âœ… HUD overlay generation

âœ… Excel reports + HTML maps

What Requires Professional Integration
1. Real GPS Tracking

Current: Simulated coordinates

Required: OBD-II hardware (see GPS section)

Provider: Fleet management companies (Geotab, Verizon Connect)

2. Privacy Protection (Face/Plate Blur)

Current: No privacy blur in V9

Required: YOLOv8 object detection + Gaussian blur pipeline

Constraint: Requires computer vision expertise + legal compliance audit

Recommendation: Partner with privacy tech specialists (Brighter AI, D-ID)

Current Status: âœ… Software ready | âš ï¸ Hardware + legal integration pending

ðŸ¤ Contributing
This is an academic/research project in prototype phase.

Open to:

ðŸŽ“ Academic collaborations

ðŸ’¼ Internship/employment in AI/ML

ðŸ™ï¸ Smart city pilot projects

ðŸ”¬ Research partnerships

Contact:

ðŸ“§ Email: 

ðŸ’¼ LinkedIn: www.linkedin.com/in/persy-maki-ndombe-b69b25250

ðŸ™ GitHub: @Persyvan

ðŸ“„ License
MIT License - See LICENSE

Copyright Â© 2026 Persy Maki Ndombe
