ðŸš— VIGIL-ROUTE: AI Road Defect Detection System

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.19-orange.svg)](https://www.tensorflow.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.9-green.svg)](https://opencv.org/)
[![YOLOv8](https://img.shields.io/badge/YOLO-v8-purple.svg)](https://github.com/ultralytics/ultralytics)
[![Accuracy](https://img.shields.io/badge/Accuracy-87.9%25-brightgreen.svg)]()
[![License](https://img.shields.io/badge/License-MIT-grey.svg)](LICENSE)

**Deep Learning system for automated road defect detection using MobileNetV2.**  
*A Privacy-First, Edge-AI solution for Smart Cities.*

Developed by **Persy Maki ND** | AI/ML Engineering Student

---

**ðŸŒ Language:** [ðŸ‡¬ðŸ‡§ English](#) | [ðŸ‡«ðŸ‡· FranÃ§ais](README_FR.md)

---

## ðŸ“Œ Project Overview

VIGIL-ROUTE is a production-ready computer vision system that identifies road defects (potholes, pavement deformations) from images and videos with **87.9% accuracy**. 

Designed to bridge the gap between reactive repairs (citizen complaints) and proactive maintenance, it introduces a novel **Danger Scoring Algorithm** that prioritizes repairs based on vehicle speed and defect severity.

### ðŸŽ¯ Key Features

- **ðŸ§  MobileNetV2 Architecture**: Lightweight CNN optimized for mobile/edge deployment
- **ðŸ“¸ Dual-Mode Operation**: 
  - **Citizen Mode**: Process photos from 311 reporting apps with EXIF GPS extraction
  - **Fleet Mode**: Real-time dashcam video analysis with HUD overlay
- **ðŸ“Š Automated Reporting**: Excel reports with color-coded urgency + Interactive HTML maps
- **ðŸŒ GPS Integration**: 
  - **Citizen**: EXIF metadata extraction (smartphone photos)
  - **Fleet**: OBD-II hardware integration (vehicle telemetry)
- **ðŸš¨ Adaptive Risk Scoring**: Speed-based urgency prioritization algorithm
- **ðŸ’§ Water Resistance**: Trained to detect water-filled potholes (rainy/winter conditions)
- **ðŸ—ºï¸ Geospatial Visualization**: Interactive Folium maps with priority markers
- **ðŸ›¡ï¸ Privacy Architecture**: YOLOv8-based detection layer (pedestrian blur operational)

---

## ðŸŽ¬ Demo & Visuals

### Fleet Mode (Real-Time Video Analysis)
*Dashcam processing with HUD overlay and privacy protection*

ðŸ“¹ **Full demo video**: [Watch on LinkedIn](#) *(coming soon)*

**Key Outputs:**
- Annotated video with detection boxes
- Real-time danger scoring
- GPS trajectory mapping
- Excel reports with frame-by-frame analysis

### Citizen Mode (311 App Simulation)
*Processing smartphone photos with automatic geolocation*

**Example Results:**

| Input Image | AI Classification | Confidence | Risk Level | Action Required |
|-------------|-------------------|------------|------------|-----------------|
| `IMG_2826.jpg` | DEFORMATION | 98% | ðŸŸ  **HIGH** | Inspection Required |
| `IMG_3288.jpg` | POTHOLE | 96% | ðŸ”´ **CRITICAL** | Immediate Repair |
| `IMG_3052.jpg` | HEALTHY ROAD | 100% | ðŸŸ¢ **NONE** | No Action |

---

## ðŸ§  The "Smart" Logic: Adaptive Risk Scoring

VIGIL-ROUTE doesn't just find holes; it assesses **danger**. A deformation at 30km/h is a nuisance; at 90km/h, it's a safety hazard.

### 1. Risk Calculation Formula

The system fuses Computer Vision confidence with vehicle telemetry data:

```python
def analyser_risque(classe, confiance, vitesse):
    """
    Calculate urgency based on:
    - Defect type (pothole = higher risk)
    - AI confidence
    - Vehicle speed (higher speed = higher danger)
    """
    if classe == 'route_saine':
        return "ðŸŸ¢ No Defect", "NONE"
    
    # Base severity score
    score_base = 1.0 if classe == 'nid_de_poule' else 0.7
    
    # Speed amplification factor (exponential)
    facteur_vitesse = 1.0 + (vitesse / 50.0) ** 1.2
    
    # Final danger score
    score_danger = (confiance * score_base) * facteur_vitesse
    
    # Urgency thresholds
    if score_danger >= 1.5:
        return "ðŸ”´ CRITICAL", "IMMEDIATE INTERVENTION"
    elif score_danger >= 1.0:
        return "ðŸŸ  HIGH", "INSPECTION REQUIRED"
    elif score_danger >= 0.7:
        return "ðŸŸ¡ MEDIUM", "MONITORING"
    else:
        return "ðŸŸ¢ LOW", "PREVENTIVE"
2. Adaptive Detection Thresholds
To reduce false positives at high speeds (safety-first approach), the model dynamically adjusts its sensitivity:

Speed Zone	Pothole Threshold	Deformation Threshold	Rationale
High (â‰¥70 km/h)	45% confidence	60% confidence	Highway speeds require conservative detection
Medium (50-69 km/h)	50% confidence	65% confidence	Urban arterial roads
Low (<50 km/h)	60% confidence	70% confidence	Residential zones allow stricter filtering
Why this matters: A false positive on a highway (70+ km/h) could cause dangerous braking. Lower thresholds = higher confidence required = fewer false alarms.

ðŸš› Deployment Modes & Hardware Requirements
Mode 1: CITIZEN (App Integration)
How it works:

Users submit photos via 311 mobile apps

System extracts GPS from EXIF metadata (iPhone/Android)

AI classifies defect type and urgency

Generates georeferenced report for city dispatch

Hardware: Smartphone only (iOS/Android)
GPS Accuracy: Â±10-50 meters (consumer GPS)
Status: âœ… Fully Operational

Mode 2: FLEET (Municipal Vehicles)
How it works:

Dashcam captures video during regular routes

AI analyzes frames in real-time (or post-processing)

OBD-II reader provides speed data for risk scoring

Outputs annotated video + georeferenced Excel reports

âš ï¸ Hardware Integration Requirements:

While the software pipeline is fully functional, real-world fleet deployment requires physical hardware integration:

Component	Purpose	Status
OBD-II GPS Reader	Real-time vehicle location + speed	âš ï¸ Hardware integration pending
Dashcam	Video capture	âœ… Any MP4 camera compatible
Edge Device	Run AI inference	âœ… Raspberry Pi 4 / Jetson Nano tested
Data Sync	OBD-II â†” Video timestamp alignment	âš ï¸ Requires fleet management integration
Recommended Devices:

FreeMatrix OBD-II Bluetooth (~$60 USD)

Verizon Hum OBD (~$10/month cellular)

Automatic Pro (~$130 WiFi + 4G)

Current Status:
âœ… Software pipeline ready
âš ï¸ Hardware integration requires municipal fleet partnership

ðŸ›¡ï¸ Privacy & Ethics Module
Compliance with privacy laws (Quebec Law 25 / GDPR) is a core design principle.

Architecture Overview
The system includes a YOLOv8 detection layer to identify personal data before storage:

Feature	Technology	Status	Note
Pedestrian Protection	YOLOv8 (Class 0)	âœ… Operational	Human detection and full-body Gaussian blur is functional
Vehicle Anonymization	YOLOv8 + Geometric Detection	âš ï¸ Prototype	License plate detection implemented as Proof-of-Concept. Production deployment requires specialized OCR/Privacy solutions
Transparency Note
As an AI Engineering student project, VIGIL-ROUTE provides the logical architecture for privacy protection. The pedestrian blur system is fully functional, but license plate anonymization would require collaboration with privacy technology specialists (e.g., Brighter AI, D-ID) for commercial deployment.

What works:

âœ… YOLOv8 detects humans reliably

âœ… Gaussian blur applied to detected regions

âœ… Privacy-first data pipeline architecture

What requires professional integration:

âš ï¸ Certified license plate detection (OCR + blur)

âš ï¸ Legal compliance audit (city legal teams)

âš ï¸ GDPR/Law 25 documentation for municipal procurement

ðŸ—ï¸ Technical Specifications
Model Architecture (V9)
Component	Details
Framework	TensorFlow 2.19.0 / Keras
Base Model	MobileNetV2 (ImageNet pretrained, frozen)
Input Shape	224Ã—224Ã—3 RGB
Classes	nid_de_poule, deformation_chaussee, route_saine
Dataset	1,584 annotated images (Montreal, Oct-Dec 2025)
Test Accuracy	87.90%
Test Loss	0.3664
Inference Time	~12ms (GPU T4) / ~120ms (CPU Colab)
Why MobileNetV2 Over Object Detection?
Design Choice Rationale:

We chose Image Classification (MobileNetV2) over Object Detection (YOLOv8) for the core defect model to maximize efficiency on edge devices.

Approach	Model	Size	Inference	Use Case
Classification	MobileNetV2	14 MB	120ms (CPU)	"Is there a defect in this road segment?"
Detection	YOLOv8	44 MB	200ms (CPU)	"Where exactly is the defect pixel-by-pixel?"
Why Classification is Sufficient:

Municipalities repair road segments (100m sections), not individual pixels. MobileNetV2 provides the necessary "Zone Alert" at 1/3 the compute cost and 1/4 the model size.

Future Upgrade (V10): YOLOv8 segmentation planned for precise depth estimation (pothole volume calculation).

ðŸ—‚ï¸ Dataset Methodology
Collection Details
Period: October - December 2025
Location: Montreal, QC, Canada (various neighborhoods)
Conditions: Winter transition (rain, wet asphalt, light snow, road salt)
Device: iPhone (simulating citizen 311 app usage)

Why Winter Data Matters:

Montreal's harsh climate creates unique challenges:

ðŸ’§ Water-filled potholes (November rains)

ðŸ‚ Autumn leaf coverage (October)

â„ï¸ Early winter conditions (December salt/snow)

This seasonal diversity ensures the model works year-round, not just in ideal sunny conditions.

Class Distribution (1,584 Images)
text
deformation_chaussee: ~650 images (41%)
nid_de_poule:         ~580 images (37%)
route_saine:          ~354 images (22%)
Per-Class Performance (Test Set):

Class	Precision	Recall	F1-Score
deformation_chaussee	85%	91%	88%
nid_de_poule	83%	74%	79%
route_saine	100%	100%	100%
Key Insight: Perfect detection of healthy roads = No false alarms wasting city resources.

ðŸš€ Quick Start
Installation
bash
git clone https://github.com/Persyvan/vigil-route.git
cd vigil-route
pip install -r requirements.txt
Usage (Inference)
python
from scripts.vigil_brain import VigilBrain

# Load Model
brain = VigilBrain('models/vigil_route_classifier_v9.keras')

# Analyze an image
result = brain.analyze('test_images/pothole_01.jpg', speed=60)
print(result)
# Output: {'class': 'nid_de_poule', 'confidence': 0.96, 'urgency': 'CRITICAL'}
ðŸ”® Roadmap & Future Work
Current Status (V9 - MVP)
âœ… MobileNetV2 core trained (87.9% accuracy)

âœ… Dual-mode pipeline operational

âœ… Privacy architecture implemented (pedestrian blur)

âœ… Risk scoring algorithm validated

âœ… Excel + HTML map generation

Next Steps
V1.1 (Hardware Integration) - 3-6 months

 OBD-II GPS testing with municipal fleet

 Real-time speed data integration

 Cloud deployment (AWS Lambda / Google Cloud Run)

V2.0 (Advanced Detection) - 6-12 months

 YOLOv8 segmentation for volumetric analysis (pothole depth)

 Certified privacy module integration

 Multi-city dataset expansion (Toronto, Quebec City)

V3.0 (Commercial Pilot) - 12+ months

 311 API integration (City of Montreal)

 Full municipal pilot program (10-vehicle fleet)

 Real-world validation study

ðŸ¤ Contact & Collaboration
This project is an Applied AI Research Prototype developed as part of my AI/ML engineering studies. I am open to collaboration with:

ðŸ™ï¸ Smart City initiatives

ðŸš— Municipal fleet management departments

ðŸ”¬ Research institutions (Computer Vision / Infrastructure)

ðŸ’¼ Engineering consulting firms

Persy Maki ND
AI/ML Engineering Student
Specialized in Computer Vision & Smart Cities

ðŸ“§ Email: persy.maki.ml@gmail.com

ðŸ’¼ LinkedIn: Persy Maki Ndombe

ðŸ™ GitHub: @Persyvan

ðŸ“ Location: Montreal, QC, Canada

ðŸ“„ License
MIT License - See LICENSE for details.

Copyright Â© 2026 Persy Maki ND

ðŸ™ Acknowledgments
Dataset: Self-collected Montreal road images (Oct-Dec 2025)

Framework: TensorFlow, Keras, OpenCV, Ultralytics (YOLOv8)

Platform: Google Colab Pro

Inspiration: Municipal 311 systems, Smart City infrastructure monitoring

â­ If this project interests you, please star the repository!

ðŸŒ Read in other languages: ðŸ‡«ðŸ‡· FranÃ§ais

Last updated: January 2026 | Model Version: V9
